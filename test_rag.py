from nexus_agent.rag import get_retriever
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

def test_rag():
    print("ğŸš€ RAG Sistemi BaÅŸlatÄ±lÄ±yor...")
    
    # 1. LLM (Beyin)
    llm = ChatOllama(model="llama3.2", temperature=0)
    
    # 2. Retriever (HafÄ±za Ã‡aÄŸÄ±rÄ±cÄ±)
    retriever = get_retriever()
    
    # 3. Prompt (Talimat)
    template = """AÅŸaÄŸÄ±daki baÄŸlam bilgisini kullanarak soruyu cevapla.
    EÄŸer cevabÄ± baÄŸlam iÃ§inde bulamazsan 'Bilmiyorum' de.
    
    BaÄŸlam: {context}
    
    Soru: {question}
    """
    prompt = ChatPromptTemplate.from_template(template)
    
    # 4. Zinciri Kur (Retrieval -> Prompt -> LLM)
    # Bu zincir:
    # - Soruyu alÄ±r
    # - Retriever'a sorup ilgili dokÃ¼manÄ± bulur (context)
    # - Soruyu ve dokÃ¼manÄ± prompt'a koyar
    # - LLM'e gÃ¶nderir
    rag_chain = (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    # 5. Soruyu Sor
    soru = "Nexus-Agent projesinin amacÄ± nedir ve hangi veritabanÄ±nÄ± kullanÄ±r?"
    print(f"\nâ“ Soru: {soru}")
    print("â³ DÃ¼ÅŸÃ¼nÃ¼yor (VeritabanÄ±na bakÄ±lÄ±yor)...")
    
    cevap = rag_chain.invoke(soru)
    
    print("\nğŸ¤– Cevap:")
    print(cevap)

if __name__ == "__main__":
    test_rag()