import os
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# 1. Sabitler
PERSIST_DIRECTORY = "./chroma_db"
DATA_PATH = "./data/dummy_info.txt"

# CPU kullanÄ±mÄ± iÃ§in ayar
EMBEDDING_DEVICE = "cpu" 

def build_vector_store():
    """Veriyi okur, parÃ§alar ve ChromaDB'ye kaydeder."""
    
    if not os.path.exists(DATA_PATH):
        print(f"âŒ HATA: {DATA_PATH} bulunamadÄ±!")
        return None

    print("ğŸ“„ DokÃ¼man okunuyor...")
    loader = TextLoader(DATA_PATH)
    docs = loader.load()

    print("âœ‚ï¸ DokÃ¼man parÃ§alanÄ±yor...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )
    splits = text_splitter.split_documents(docs)

    print(f"ğŸ§  Embedding yapÄ±lÄ±yor... (Cihaz: {EMBEDDING_DEVICE})")
    # BURAYI DEÄÄ°ÅTÄ°RDÄ°K: model_kwargs ekledik
    embedding_function = HuggingFaceEmbeddings(
        model_name="all-MiniLM-L6-v2",
        model_kwargs={'device': EMBEDDING_DEVICE}
    )

    print("ğŸ’¾ VeritabanÄ±na kaydediliyor...")
    vectorstore = Chroma.from_documents(
        documents=splits,
        embedding=embedding_function,
        persist_directory=PERSIST_DIRECTORY
    )
    
    print(f"âœ… BaÅŸarÄ±lÄ±! {len(splits)} parÃ§a vektÃ¶r veritabanÄ±na eklendi.")
    return vectorstore

def get_retriever():
    """KayÄ±tlÄ± veritabanÄ±nÄ± getirir."""
    # BURAYI DEÄÄ°ÅTÄ°RDÄ°K: model_kwargs ekledik
    embedding_function = HuggingFaceEmbeddings(
        model_name="all-MiniLM-L6-v2",
        model_kwargs={'device': EMBEDDING_DEVICE}
    )
    
    vectorstore = Chroma(
        persist_directory=PERSIST_DIRECTORY, 
        embedding_function=embedding_function
    )
    return vectorstore.as_retriever(search_kwargs={"k": 3})

if __name__ == "__main__":
    build_vector_store()