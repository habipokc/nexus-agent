from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# Sabitler
PERSIST_DIRECTORY = "./chroma_db"
# Embedding fonksiyonunu tanÄ±mlamak zorundayÄ±z Ã§Ã¼nkÃ¼ Chroma veriyi geri okurken
# "Hangi modelle gÃ¶mdÃ¼ysen onunla okurum" der (boyut kontrolÃ¼ iÃ§in).
embedding_function = HuggingFaceEmbeddings(
    model_name="all-MiniLM-L6-v2",
    model_kwargs={'device': 'cpu'}
)

def inspect():
    print("ğŸ” VeritabanÄ± AÃ§Ä±lÄ±yor...")
    
    # VeritabanÄ±na baÄŸlan
    db = Chroma(
        persist_directory=PERSIST_DIRECTORY,
        embedding_function=embedding_function
    )
    
    # TÃ¼m verileri Ã§ek (ID'ler, Metadata, DokÃ¼manlar ve VektÃ¶rler)
    # include=['embeddings'] demezsek vektÃ¶r sayÄ±larÄ±nÄ± getirmez, sadece metni getirir.
    data = db.get(include=['documents', 'metadatas', 'embeddings'])
    
    count = len(data['ids'])
    print(f"ğŸ“‚ Toplam DokÃ¼man SayÄ±sÄ±: {count}\n")
    
    if count > 0:
        print("--- Ã–rnek KayÄ±t (Ä°lk SÄ±radaki) ---")
        print(f"ğŸ†” ID: {data['ids'][0]}")
        print(f"ğŸ“„ Metin: {data['documents'][0][:100]}...") # Ä°lk 100 karakter
        
        vector = data['embeddings'][0]
        print(f"ğŸ§® VektÃ¶r Boyutu: {len(vector)} (Bu model 384 boyutlu vektÃ¶r Ã¼retir)")
        print(f"ğŸ”¢ VektÃ¶rÃ¼n Ä°lk 5 SayÄ±sÄ±: {vector[:5]}") # Hepsini basarsak ekran dolar
        print("   (Bu sayÄ±lar, metnin uzaydaki koordinatlarÄ±dÄ±r)")

if __name__ == "__main__":
    inspect()